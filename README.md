# Data Cleaning with Python

## Introduction

Welcome to this step-by-step guide on data cleaning using Python libraries..

Data Cleaning is the process of handling missing values,removing and or changing wrong,incomplete and duplicated data in a dataset to ensure that the data is accurate for analysis.

Data analysts are essential in helping organizations gain valuable insights into the expanse of data that they have, and  to help reveal valuable information.

Well,before doing that,a data analyst has to turn the raw data provided into information that is understandable and readable as well.

This involves,among other things,correcting any inaccurate data,identifying missing data and converting data from one data type to another.

To be honest,as a data analyst,data cleaning has to be the most critical step; ensuring that the data is accurate,well sorted and formatted as having wrong data can lead to inconsistency in the output leading to mediocre interpretation of the results and well,who wants that?

## Goals of Data Cleaning

    1.Handling missing values:dropping the missing values and filling in the missig values.

    2.changing the data types-parsing dates.

    3.Handling inconsistent data entry.

    4.Handling outliers.

## Libraries

This whole project will incorporate the use of several python libraries for data cleaning,including:

      1.Numpy for mathematical operations.

      2.Pandas to read the data file,change the dataset into a dataframe for cleaning and exploring the data.

      3.Matplotlib to visualize the dataset.

## Installation

This repository has been built with Python 3.

It uses the latest release of each library, however,if you run into an issue,try upgrading the library.

## For Starters

To work on a similar project,you need to;

1.Create a repository on Github for this project.

2.Create a virtual environment where you will work on this project.

3.Clone your repository.

4.Activate your virtual environment.

5.Install the above mentioned libraries using (pip install (pandas)).

6.Launch Jupyter Notebooks.

7.Navigate to the cloned repository in your Jupyter Notebook interface.

8.Import the installed libraries(import pandas as pd).

9.Load the dataset(df = pd.read_csv('your_dataset.csv'))

## Dataset

The dataset used in this project was downloaded from Kaggle datasets,you can access it from the folder named (Open Airbnb Data.xlsx)

The final cleaned dataset is saved in the file named (Clean Airbnb_data.xlsx).

## Contributions

If you find any issues or you wold like to contribute, feel free to submit an Issue or Pull Request @IVYMWAI

I appreciate your input!
